{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eba647a-ef1e-41b3-bd62-b75138def1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, collect_list, concat_ws, first\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1a369ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création Session Spark\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"ALS Recommendation System\")\n",
    "         .config(\"spark.hadoop.fs.defaultFS\", \"hdfs://namenode:9000\")\n",
    "         .config(\"spark.driver.memory\", \"4g\")  # Mémoire pour le driver\n",
    "         .config(\"spark.executor.memory\", \"4g\")  # Mémoire pour les executors\n",
    "         .config(\"spark.sql.shuffle.partitions\", \"200\")  # Nombre de partitions\n",
    "         .config(\"spark.driver.maxResultSize\", \"2g\")  # Taille max des résultats\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a1a1f9-9b50-42e1-8c84-e1c7c18e8764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie = spark.read.csv(\"/data/movie.csv\", header=True, inferSchema=True)\n",
    "\n",
    "movie.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a38a04-e287-483c-8772-1d48ebbb698a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating = spark.read.csv(\"/data/rating.csv\", header=True, inferSchema=True)\n",
    "rating.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0318548c-bc33-4dcc-b528-8a2ea0a0ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes movieId = 0\n",
      "Nombre de valeurs manquantes title = 0\n",
      "Nombre de valeurs manquantes genres = 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "# Compter les valeurs nulles pour chaque colonne du DataFrame `movie`\n",
    "for column in movie.columns:\n",
    "    null_count = movie.select(count(when(col(column).isNull(), 1)).alias(\"null_count\")).collect()[0][\"null_count\"]\n",
    "    print(f\"Nombre de valeurs manquantes {column} = {null_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082fe7f8-d0ee-4d5e-8eeb-39c6988a6ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de valeurs manquantes userId = 0\n",
      "Nombre de valeurs manquantes movieId = 0\n",
      "Nombre de valeurs manquantes rating = 0\n",
      "Nombre de valeurs manquantes timestamp = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compter les valeurs nulles pour chaque colonne du DataFrame `rating`\n",
    "for column in rating.columns:\n",
    "    null_count = rating.select(count(when(col(column).isNull(), 1)).alias(\"null_count\")).collect()[0][\"null_count\"]\n",
    "    print(f\"Nombre de valeurs manquantes {column} = {null_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58602785-1a75-4d28-9c96-6a21401dad45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de doublons dans movie = 0\n",
      "Nombre de doublons dans rating = 0\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le nombre de doublons dans `movie`\n",
    "movie_dupes = movie.count() - movie.dropDuplicates().count()\n",
    "print(f\"Nombre de doublons dans movie = {movie_dupes}\")\n",
    "\n",
    "# Vérifier le nombre de doublons dans `rating`\n",
    "rating_dupes = rating.count() - rating.dropDuplicates().count()\n",
    "print(f\"Nombre de doublons dans rating = {rating_dupes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e3ff45-b0dc-47c5-9f66-c0d10a50601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le schéma des colonnes pour `movie`\n",
    "movie.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b5e82e-1f76-4844-abaa-3272ee23d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vérifier le schéma des colonnes pour `rating`\n",
    "rating.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf20a31-18e1-479c-b432-076b2e0dcb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Étape 1 : Préparer les données d'entraînement et de test\n",
    "# Fractionner les données en train et test\n",
    "(training, test) = rating.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Étape 2 : Configurer le modèle ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    nonnegative=True,  # Garantit que les prédictions sont positives\n",
    "    coldStartStrategy=\"drop\",  # Ignore les prédictions avec données inconnues\n",
    "    rank=10,  # Nombre de facteurs latents\n",
    "    maxIter=10  # Nombre d'itérations\n",
    ")\n",
    "\n",
    "\n",
    "# Étape 3 : Entraîner le modèle ALS\n",
    "als_model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3863f4-83b6-4a83-9e89-09c2f9ec19a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3096bfe-0ff8-490c-ae8e-866e9b3b76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le RMSE du modèle ALS est : 0.817251011276976\n"
     ]
    }
   ],
   "source": [
    "predictions = als_model.transform(test)\n",
    "\n",
    "# Configurer l'évaluateur de régression pour RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calculer le RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Le RMSE du modèle ALS est : {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c79a76fe-68e5-4f52-b18f-df050267cf45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le MAE du modèle ALS est : 0.6388887185607606\n"
     ]
    }
   ],
   "source": [
    "# Configurer l'évaluateur de régression pour RMSE\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    metricName=\"mae\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calculer le mae\n",
    "mae = mae_evaluator.evaluate(predictions)\n",
    "print(f\"Le MAE du modèle ALS est : {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c5a00-d798-4582-9bde-9385f7c8ef48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "115f3e7a-5b5c-4f11-bc03-84e948230b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle ALS sauvegardé sur HDFS.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le modèle sur HDFS\n",
    "als_model.write().overwrite().save(\"hdfs://namenode:9000/model/als_model\")\n",
    "print(\"Modèle ALS sauvegardé sur HDFS.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75895b6-fc69-4c73-8978-291e7296d3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
